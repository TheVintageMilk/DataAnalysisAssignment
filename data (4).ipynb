{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Running application"
      ],
      "metadata": {
        "id": "mNd4O34C1P09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nocL42qz5AwM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/data assignment/merging'\n",
        "\n",
        "%ls\n",
        "\n",
        "!pip install streamlit\n",
        "\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "\n",
        "\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging used datasets"
      ],
      "metadata": {
        "id": "7jrEJvvd7WwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the specific file paths and their location types\n",
        "files_info = {\n",
        "    \"/content/merging/PRSA_Data_Dingling_20130301-20170228.csv\": \"Rural\",\n",
        "    \"/content/merging/PRSA_Data_Gucheng_20130301-20170228.csv\": \"Suburban\",\n",
        "    \"/content/merging/PRSA_Data_Nongzhanguan_20130301-20170228.csv\": \"Industrial\",\n",
        "    \"/content/merging/PRSA_Data_Tiantan_20130301-20170228.csv\": \"Urban\"\n",
        "}\n",
        "\n",
        "# Read and label each file\n",
        "dataframes = []\n",
        "for path, location in files_info.items():\n",
        "    df = pd.read_csv(path)\n",
        "    df['LocationType'] = location  # Add a column to tag location type\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Merge all into a single DataFrame\n",
        "merged_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Save the merged dataset to your workspace\n",
        "merged_df.to_csv(\"/content/merged_PRSA_data.csv\", index=False)\n",
        "missing = df.isnull().sum()\n",
        "\n",
        "print(\"Files successfully merged and saved as 'merged_PRSA_data.csv'\")\n"
      ],
      "metadata": {
        "id": "Gj7bWvfm7dXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying Data showing total errors"
      ],
      "metadata": {
        "id": "lzFd0aQD8FNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the merged dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/data assignment/merging/merged_PRSA_data.csv')\n",
        "\n",
        "\n",
        "# Check how many missing values per column along with other info\n",
        "missing = df.isnull().sum()\n",
        "\n",
        "print(\"Number of rows and columns:\\n\", df.shape)\n",
        "print(\"Column names and data types:\\n\", df.dtypes)\n",
        "print(\"Sample of dataset:\\n\", df.head())\n",
        "print(\"Missing values:\\n\", missing)\n",
        "\n",
        "# Visualise the missing data\n",
        "import missingno as msno\n",
        "msno.matrix(df)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UN4zOSfo8Ip1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid clean up of data"
      ],
      "metadata": {
        "id": "hRJqc5K08uh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#missingno for null visualization\n",
        "import missingno as msno\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/merged_PRSA_data.csv')\n",
        "print(\"Initial shape:\", df.shape)\n",
        "\n",
        "# define data column types\n",
        "critical_columns = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'wd']\n",
        "weather_columns = ['RAIN', 'TEMP', 'DEWP', 'PRES', 'WSPM']\n",
        "\n",
        "# Drop rows where important pollutants are missing\n",
        "df = df.dropna(subset=critical_columns)\n",
        "\n",
        "# Fill missing weather data with median value\n",
        "for col in weather_columns:\n",
        "    if col in df.columns:\n",
        "        median_value = df[col].median()\n",
        "        df[col] = df[col].fillna(median_value)\n",
        "\n",
        "# Double-check if any missing values left\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualise the missing data\n",
        "import missingno as msno\n",
        "msno.matrix(df)\n",
        "plt.show()\n",
        "\n",
        "df.to_csv('merged_cleaned_PRSA_data.csv', index=False)\n",
        "\n",
        "print(\"\\nData fully cleaned and saved\")"
      ],
      "metadata": {
        "id": "Jx-mi3YA8xht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA and correlation"
      ],
      "metadata": {
        "id": "ii1_bJA99NBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load in the clean data\n",
        "df = pd.read_csv('merged_cleaned_PRSA_data.csv')\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "relevant_columns = [\n",
        "    'PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3',\n",
        "    'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'\n",
        "]\n",
        "\n",
        "x_labels = [\n",
        "    \"PM2.5 Concentration (μg/m³)\",     # PM2.5\n",
        "    \"PM10 Concentration (μg/m³)\",      # PM10\n",
        "    \"SO₂ Concentration (μg/m³)\",       # SO2\n",
        "    \"NO₂ Concentration (μg/m³)\",       # NO2\n",
        "    \"CO Concentration (mg/m³)\",        # CO\n",
        "    \"O₃ Concentration (μg/m³)\",        # O3\n",
        "    \"Temperature (°C)\",                # TEMP\n",
        "    \"Pressure (hPa)\",                  # PRES\n",
        "    \"Dew Point (°C)\",                  # DEWP\n",
        "    \"Rainfall (mm)\",                   # RAIN\n",
        "    \"Wind Speed (m/s)\"                 # WSPM\n",
        "]\n",
        "\n",
        "\n",
        "#  Summary Statistics\n",
        "print(\"\\nSummary Statistics:\\n\")\n",
        "print(df[relevant_columns].describe().round(2))\n",
        "\n",
        "#  Histograms for distribution\n",
        "print(\"\\nHistograms:\\n\")\n",
        "df[relevant_columns].hist(bins=30, figsize=(15, 10), color='skyblue', edgecolor='black')\n",
        "plt.suptitle('Histograms of Relevant Variables', fontsize=18)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n",
        "\n",
        "# First, import the function from scipy\n",
        "from scipy.stats import skew\n",
        "\n",
        "# Loop through and print skewness\n",
        "for col in relevant_columns:\n",
        "    skewness = skew(df[col].dropna())  # dropna() to avoid issues with missing values\n",
        "    print(f\"Skewness for {col}: {skewness:.2f}\")\n",
        "\n",
        "print(\"\\n Insight: The distribution of pollutant levels (PM2.5, PM10, CO, NO2) is right-skewed, suggesting that extreme pollution events occur less frequently but have a significant impact.\")\n",
        "\n",
        "#  Boxplots to spot outliers\n",
        "print(\"\\nBoxplots:\\n\")\n",
        "plots_per_row = 3\n",
        "\n",
        "for i in range(0, len(relevant_columns), plots_per_row):\n",
        "    fig, axes = plt.subplots(1, plots_per_row, figsize=(18, 5))  # 1 row, 3 columns\n",
        "\n",
        "    for j in range(plots_per_row):\n",
        "        if i + j < len(relevant_columns):\n",
        "            sns.boxplot(data=df, x=relevant_columns[i + j], ax=axes[j])\n",
        "            axes[j].set_title(f'Boxplot of {relevant_columns[i + j]}')\n",
        "            axes[j].set_xlabel(x_labels[i + j])\n",
        "        else:\n",
        "            axes[j].set_visible(False)  # Hide empty subplots if any\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n Insight: The boxplots revealed that variables such as PM2.5, PM10, SO2, NO2, CO, O3, Rain, and WSPM exhibited a large number of outliers, especially \\n toward higher values, indicating right-skewed distributions and significant variability.\"\n",
        "\"\\n In contrast, meteorological variables such as Temperature (TEMP), Pressure (PRES), and Dew Point (DEWP) showed relatively symmetrical distributions with \\n fewer outliers, suggesting more stable behavior across the dataset. This supports the previous histograms being right skewed\")\n"
      ],
      "metadata": {
        "id": "qwOGiDWu9QvN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}